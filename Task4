import zipfile
import os

# Path to your zip file
zip_path = '/content/Rice_Image_Dataset.zip'
extract_path = '/content/Rice_Image_Dataset'

# Unzipping the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Check if the extraction worked
print(os.listdir(extract_path))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Parameters
img_height, img_width = 150, 150
batch_size = 32

# Create ImageDataGenerators for training and validation sets
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Now point to the extracted directory
train_dir = '/content/Rice_Image_Dataset/Rice_Image_Dataset/train'  # Update to the correct path of your extracted folder
val_dir = '/content/Rice_Image_Dataset/Rice_Image_Dataset/test'  # Update to the correct path of your validation data

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

def build_model(num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Build model
num_classes = len(train_generator.class_indices)
model = build_model(num_classes)
model.summary()

from tensorflow.keras.optimizers import Adam

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

# Evaluate the model
val_loss, val_accuracy = model.evaluate(val_generator)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_accuracy}')

import numpy as np
from tensorflow.keras.preprocessing import image

def predict_image(img_path):
    img = image.load_img(img_path, target_size=(img_height, img_width))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0

    predictions = model.predict(img_array)
    class_idx = np.argmax(predictions[0])
    class_labels = list(train_generator.class_indices.keys())
    return class_labels[class_idx]

# Predict new image
new_image_path = '/content/Basmati.jpeg'  # Replace with your image path
predicted_class = predict_image(new_image_path)
print(f'Predicted Class: {predicted_class}')

import matplotlib.pyplot as plt

def plot_training_history(history):
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

plot_training_history(history)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D

def build_finetuned_model(num_classes):
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    for layer in base_model.layers:
        layer.trainable = False

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Build fine-tuned model
fine_tuned_model = build_finetuned_model(num_classes=5)
fine_tuned_model.summary()

# Train fine-tuned model
history_fine_tuned = fine_tuned_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=10,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

# Evaluate fine-tuned model
val_loss, val_accuracy = fine_tuned_model.evaluate(val_generator)
print(f'Validation Loss (Fine-Tuned): {val_loss}')
print(f'Validation Accuracy (Fine-Tuned): {val_accuracy}')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(cm, class_names):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.show()

def plot_class_distribution(predictions, class_names):
    unique, counts = np.unique(predictions, return_counts=True)
    class_distribution = dict(zip(class_names, counts))
    
    df = pd.DataFrame(list(class_distribution.items()), columns=['Class', 'Count'])
    
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Class', y='Count', data=df, palette='viridis')
    plt.xlabel('Class')
    plt.ylabel('Count')
    plt.title('Class Distribution of Predictions')
    plt.xticks(rotation=45)
    plt.show()

# Make predictions on validation set
val_predictions = fine_tuned_model.predict(val_generator)
val_predictions_classes = np.argmax(val_predictions, axis=1)
val_true_classes = val_generator.classes

# Compute confusion matrix
cm = confusion_matrix(val_true_classes, val_predictions_classes)

# Plot confusion matrix
plot_confusion_matrix(cm, class_names=list(train_generator.class_indices.keys()))

# Plot class distribution
plot_class_distribution(val_predictions_classes, class_names=list(train_generator.class_indices.keys()))
